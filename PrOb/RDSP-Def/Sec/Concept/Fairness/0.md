Ti=FAIRNESS TERMS

Modeling.Ti=Modeling

Modeling.sec=Modeling is any activity that might be described as inferential, causal, predictive, or generative modeling in nature.  The most common activities relate to the creation or management of feature or input data, the preprocessing or engineering of such feature or input data, and clustering, classification, regression, hyperparameter optimization, generation, or simulation using such feature or input data.  The output of a Modeling activity is referred to as a Model.

Modeling.Example=A classification algorithm used to screen resumes for hiring is a Model.  The process of obtaining the data from an HR system, engineering features from this data, and fitting a decision tree to the data is Modeling.

Modeling.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Algorithmic_Bias.Ti=Algorithmic Bias

Algorithmic_Bias.sec=A Model can be described as having Algorithmic Bias when it produces systematically unfair inferences or outcomes.  Algorithmic Bias can occur in any type of Modeling or Model.

Algorithmic_Bias.SeeAlso=Training Data Bias, Target Bias
Example: A classification algorithm is used to screen resumes for hiring.  The algorithm systematically rejects older applicants.

Algorithmic_Bias.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Training_Data_Bias.Ti=Training Data Bias

Training_Data_Bias.sec=A Model can be described as having Training Data Bias when the features or inputs used in Modeling result in Algorithmic Bias.  Training Data Bias can arise in a number of ways, such as the manner of Data Subject identification or the inclusion, omission, processing, or annotation of attributes related to the Data Subjects.

Training_Data_Bias.SeeAlso=Algorithmic Bias, Target Bias

Training_Data_Bias.Example=A classification algorithm is used to screen resumes for hiring.  The algorithm is trained on a Dataset that does not include any older applicants.

Training_Data_Bias.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Target_Bias.Ti=Target Bias

Target_Bias.sec=A Model can be described as having Target Bias when the targets, labels, or objectives used in Modeling result in Algorithmic Bias.  There are various ways in which Target Bias is introduced, such as the framing of the research problem, the manner of Data Subject identification or sampling, or the inclusion, omission, processing, or annotation of attributes related to the Data Subjects.

Target_Bias.SeeAlso=Algorithmic Bias, Training Bias

Target_Bias.Example=A classification algorithm is used to screen resumes for hiring.  The target used to fit the classification algorithm is based on whether the applicant will remain at the Organization for at least 10 years.

Target_Bias.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Fairness_Metric.Ti=Fairness Metric

Fairness_Metric.sec=A Fairness Metric is a quantitative measure of algorithmic bias in a Model.  There are a wide range of such metrics, some of which are focused on specific outcomes or units, such as wealth or salary.

Fairness_Metric.SeeAlso=Statistical Parity, Predictive Parity, Theil Index

Fairness_Metric.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Statistical_Parity.Ti=Statistical Parity

Statistical_Parity.sec=Statistical Parity is a fairness measure based on the difference in a Model’s positive rate based on a protected Attribute.  A Model can be said to exhibit Statistical Parity if its positive rate is not statistically-significantly different across selected groups.

Statistical_Parity.SeeAlso=Predictive Parity, Equal Opportunity, Theil Index

Statistical_Parity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Predictive_Parity.Ti=Predictive Parity

Predictive_Parity.sec=Statistical Parity is a fairness measure based on the difference in a Model’s precision based on a protected Attribute.  A Model can be said to exhibit Predictive Parity if its precision is not statistically-significantly different across selected groups.

Predictive_Parity.SeeAlso=Statistical Parity, Equal Opportunity, Theil Index

Predictive_Parity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Equal_Opportunity.Ti=Equal Opportunity

Equal_Opportunity.sec=Statistical Parity is a fairness measure based on the difference in a Model’s false negative rate based on a protected Attribute.  A Model can be said to exhibit Equal Opportunity if its false negative rate is not statistically-significantly different across selected groups.

Equal_Opportunity.SeeAlso=Statistical Parity, Predictive Parity, Theil Index

Equal_Opportunity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Theil_Index.Ti=Theil Index

Theil_Index.sec=The Theil Index is an inequality measure based on the degree to which an income or wealth distribution varies from a baseline distribution.  Larger values correspond to more inequality, not more fairness.

Theil_Index.SeeAlso=Statistical Parity, Predictive Parity, Equal Opportunity, Atkinson Index

Theil_Index.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Atkinson_Index.Ti=Atkinson Index

Atkinson_Index.sec=The Atkinson Index is an inequality measure based on normalizing the Theil index.  Values closer to 1 indicate more inequality, whereas values closer to 0 indicate more equality of income.

Atkinson_Index.SeeAlso=Statistical Parity, Predictive Parity, Equal Opportunity, Theil Index

Atkinson_Index.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

sec=<ol><li>{Modeling.Sec}</li><li>{Algorithmic_Bias.Sec}</li><li>{Training_Data_Bias.Sec}</li><li>{Target_Bias.Sec}</li><li>{Fairness_Metric.Sec}</li><li>{Statistical_Parity.Sec}</li><li>{Predictive_Parity.Sec}</li><li>{Equal_Opportunity.Sec}</li><li>{Theil_Index.Sec}</li><li>{Atkinson_Index.Sec}</li></ol>

=[G/Z/Base]